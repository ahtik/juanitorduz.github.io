{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Plots Text Generation with Keras\n",
    "\n",
    "In this post I show some text generation experiments I ran using [LSTM](https://en.wikipedia.org/wiki/Long_short-term_memory) with [Keras](https://keras.io). For the preprocessing and tokenization I used [SpaCy](https://spacy.io). The aim is not to present a completed project, but rather a first step which should be iterated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "There are many great resources and blog posts about the subject (and similar experiments). Here I mention the ones I found particularly useful:\n",
    "\n",
    "- Online Resources:\n",
    "    - [Deep Learning Specialization](https://www.deeplearning.ai), [Coursera](https://www.coursera.org) by [Andrew Ng](https://www.andrewng.org).\n",
    "\n",
    "    - [NLP with Python](https://www.udemy.com/nlp-natural-language-processing-with-python/), [Udemy](https://www.udemy.com/) by [Jose Portilla](https://www.linkedin.com/in/jmportilla/).\n",
    "    \n",
    "**Remark:** From this last course I took most of the code in this experiment (check out the complete series of videos!).\n",
    "\n",
    "- Books:\n",
    "\n",
    "    - [Deep Learning with R](https://www.manning.com/books/deep-learning-with-r), by [Fran√ßois Chollet](https://www.linkedin.com/in/fchollet/) and [J. J. Allaire](https://www.linkedin.com/in/jjallaire/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Set\n",
    "\n",
    "[Wikipedia Movie Plots](https://www.kaggle.com/jrobischon/wikipedia-movie-plots)\n",
    "\n",
    "- Source: [Kaggle](https://www.kaggle.com/).\n",
    "\n",
    "- Description: *Plot summary descriptions scraped from Wikipedia*.\n",
    "\n",
    "Our aim is to train a text generator algorithm able to write plots for horror movies (why horror? no particular reason)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1901</td>\n",
       "      <td>Kansas Saloon Smashers</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...</td>\n",
       "      <td>A bartender is working at a saloon, serving dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901</td>\n",
       "      <td>Love by the Light of the Moon</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Love_by_the_Ligh...</td>\n",
       "      <td>The moon, painted with a smiling face hangs ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1901</td>\n",
       "      <td>The Martyred Presidents</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Martyred_Pre...</td>\n",
       "      <td>The film, just over a minute long, is composed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1901</td>\n",
       "      <td>Terrible Teddy, the Grizzly King</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Terrible_Teddy,_...</td>\n",
       "      <td>Lasting just 61 seconds and consisting of two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>Jack and the Beanstalk</td>\n",
       "      <td>American</td>\n",
       "      <td>George S. Fleming, Edwin S. Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jack_and_the_Bea...</td>\n",
       "      <td>The earliest known adaptation of the classic f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Release Year                             Title Origin/Ethnicity  \\\n",
       "0          1901            Kansas Saloon Smashers         American   \n",
       "1          1901     Love by the Light of the Moon         American   \n",
       "2          1901           The Martyred Presidents         American   \n",
       "3          1901  Terrible Teddy, the Grizzly King         American   \n",
       "4          1902            Jack and the Beanstalk         American   \n",
       "\n",
       "                             Director Cast    Genre  \\\n",
       "0                             Unknown  NaN  unknown   \n",
       "1                             Unknown  NaN  unknown   \n",
       "2                             Unknown  NaN  unknown   \n",
       "3                             Unknown  NaN  unknown   \n",
       "4  George S. Fleming, Edwin S. Porter  NaN  unknown   \n",
       "\n",
       "                                           Wiki Page  \\\n",
       "0  https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...   \n",
       "1  https://en.wikipedia.org/wiki/Love_by_the_Ligh...   \n",
       "2  https://en.wikipedia.org/wiki/The_Martyred_Pre...   \n",
       "3  https://en.wikipedia.org/wiki/Terrible_Teddy,_...   \n",
       "4  https://en.wikipedia.org/wiki/Jack_and_the_Bea...   \n",
       "\n",
       "                                                Plot  \n",
       "0  A bartender is working at a saloon, serving dr...  \n",
       "1  The moon, painted with a smiling face hangs ov...  \n",
       "2  The film, just over a minute long, is composed...  \n",
       "3  Lasting just 61 seconds and consisting of two ...  \n",
       "4  The earliest known adaptation of the classic f...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data. \n",
    "movies_raw_df = pd.read_csv('wiki_movie_plots_deduped.csv')\n",
    "\n",
    "movies_raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_to_select = ((movies_raw_df['Genre'] == 'horror') &\n",
    "                    # Restrict to Amerian movies. \n",
    "                    (movies_raw_df['Origin/Ethnicity'] == 'American') &\n",
    "                    # Only movies from 2000.\n",
    "                    (movies_raw_df['Release Year'] > 1999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last two conditions are just to make the data set smaller (as this is juat an experiment). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13617    In November 1999, tourists and fans of The Bla...\n",
       "13640    Matthew Van Helsing, the alleged descendant of...\n",
       "13681    A small group of fervent Roman Catholics belie...\n",
       "13731    Cotton Weary, now living in Los Angeles and th...\n",
       "13763    Amy Mayfield, a student at a prestigious film ...\n",
       "Name: Plot, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horror_df = movies_raw_df[movies_to_select]['Plot']\n",
    "\n",
    "horror_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horror_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data \n",
    "\n",
    "We are going to use [SpaCy](https://spacy.io) for the tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all plots into a string.\n",
    "horror_str = horror_df.str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load language model. \n",
    "nlp = spacy.load('en', disable = ['parser', 'tagger', 'ner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data set is big, it might be ncessary to increate `nlp.max_length`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a function to extract the tokens (words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(doc_text):\n",
    "    # This patter is a modification of the defaul filter of the \n",
    "    # Tokenizer() object in keras.preprocessing.text. \n",
    "    # It just indicates which patters no skip.\n",
    "    skip_pattern = '\\r\\n \\n\\n \\n\\n\\n!\"-#$%&()--.*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r '\n",
    "    \n",
    "    tokens = [token.text.lower() for token in nlp(doc_text) if token.text not in skip_pattern]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tokens.\n",
    "tokens = get_tokens(horror_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in', 'november', '1999', 'tourists', 'and', 'fans', 'of', 'the', 'blair']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us see the first tokens\n",
    "tokens[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165870"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the number of tokens list.\n",
    "len(tokens) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "The idea to construct the feature matrix for the model is to generate sequences of words of length `len_0` + 1, where the first `len_0` words define the features and the last word the target. That is, with a sequence of words of length `len_0` we predict the next word. The model is then set as a multi-class classification problem.\n",
    "\n",
    "\n",
    "For this use case, we are going to set `len_0` = 25. \n",
    "\n",
    "For example, the first observation would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in',\n",
       " 'november',\n",
       " '1999',\n",
       " 'tourists',\n",
       " 'and',\n",
       " 'fans',\n",
       " 'of',\n",
       " 'the',\n",
       " 'blair',\n",
       " 'witch',\n",
       " 'project',\n",
       " 'descend',\n",
       " 'on',\n",
       " 'the',\n",
       " 'small',\n",
       " 'town',\n",
       " 'of',\n",
       " 'burkittsville',\n",
       " 'maryland',\n",
       " 'where',\n",
       " 'the',\n",
       " 'film',\n",
       " 'is',\n",
       " 'set',\n",
       " 'local']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_0 = 25\n",
    "\n",
    "tokens[0:len_0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resident']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[len_0:len_0 + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now generate the sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len_0 + 1\n",
    "\n",
    "text_sequences = []\n",
    "\n",
    "for i in range(train_len, len(tokens)):\n",
    "    # Construct sequence.\n",
    "    seq = tokens[i - train_len: i]\n",
    "    # Append.\n",
    "    text_sequences.append(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, the first sequence is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in november 1999 tourists and fans of the blair witch project descend on the small town of burkittsville maryland where the film is set local resident'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_sequences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see the first five sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in november 1999 tourists and fans of the blair witch project descend on the small town of burkittsville maryland where the film is set local resident\n",
      "-----\n",
      "november 1999 tourists and fans of the blair witch project descend on the small town of burkittsville maryland where the film is set local resident jeff\n",
      "-----\n",
      "1999 tourists and fans of the blair witch project descend on the small town of burkittsville maryland where the film is set local resident jeff a\n",
      "-----\n",
      "tourists and fans of the blair witch project descend on the small town of burkittsville maryland where the film is set local resident jeff a former\n",
      "-----\n",
      "and fans of the blair witch project descend on the small town of burkittsville maryland where the film is set local resident jeff a former psychiatric\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 5):\n",
    "    print(' '.join(text_sequences[i]))\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also see this as a data frame. The last column will define the label for the classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>november</td>\n",
       "      <td>1999</td>\n",
       "      <td>tourists</td>\n",
       "      <td>and</td>\n",
       "      <td>fans</td>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>blair</td>\n",
       "      <td>witch</td>\n",
       "      <td>project</td>\n",
       "      <td>...</td>\n",
       "      <td>burkittsville</td>\n",
       "      <td>maryland</td>\n",
       "      <td>where</td>\n",
       "      <td>the</td>\n",
       "      <td>film</td>\n",
       "      <td>is</td>\n",
       "      <td>set</td>\n",
       "      <td>local</td>\n",
       "      <td>resident</td>\n",
       "      <td>jeff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999</td>\n",
       "      <td>tourists</td>\n",
       "      <td>and</td>\n",
       "      <td>fans</td>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>blair</td>\n",
       "      <td>witch</td>\n",
       "      <td>project</td>\n",
       "      <td>descend</td>\n",
       "      <td>...</td>\n",
       "      <td>maryland</td>\n",
       "      <td>where</td>\n",
       "      <td>the</td>\n",
       "      <td>film</td>\n",
       "      <td>is</td>\n",
       "      <td>set</td>\n",
       "      <td>local</td>\n",
       "      <td>resident</td>\n",
       "      <td>jeff</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tourists</td>\n",
       "      <td>and</td>\n",
       "      <td>fans</td>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>blair</td>\n",
       "      <td>witch</td>\n",
       "      <td>project</td>\n",
       "      <td>descend</td>\n",
       "      <td>on</td>\n",
       "      <td>...</td>\n",
       "      <td>where</td>\n",
       "      <td>the</td>\n",
       "      <td>film</td>\n",
       "      <td>is</td>\n",
       "      <td>set</td>\n",
       "      <td>local</td>\n",
       "      <td>resident</td>\n",
       "      <td>jeff</td>\n",
       "      <td>a</td>\n",
       "      <td>former</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>fans</td>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>blair</td>\n",
       "      <td>witch</td>\n",
       "      <td>project</td>\n",
       "      <td>descend</td>\n",
       "      <td>on</td>\n",
       "      <td>the</td>\n",
       "      <td>...</td>\n",
       "      <td>the</td>\n",
       "      <td>film</td>\n",
       "      <td>is</td>\n",
       "      <td>set</td>\n",
       "      <td>local</td>\n",
       "      <td>resident</td>\n",
       "      <td>jeff</td>\n",
       "      <td>a</td>\n",
       "      <td>former</td>\n",
       "      <td>psychiatric</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows √ó 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2     3      4      5        6        7   \\\n",
       "0  november      1999  tourists   and   fans     of      the    blair   \n",
       "1      1999  tourists       and  fans     of    the    blair    witch   \n",
       "2  tourists       and      fans    of    the  blair    witch  project   \n",
       "3       and      fans        of   the  blair  witch  project  descend   \n",
       "\n",
       "        8        9      ...                  16        17     18    19     20  \\\n",
       "0    witch  project     ...       burkittsville  maryland  where   the   film   \n",
       "1  project  descend     ...            maryland     where    the  film     is   \n",
       "2  descend       on     ...               where       the   film    is    set   \n",
       "3       on      the     ...                 the      film     is   set  local   \n",
       "\n",
       "         21        22        23        24           25  \n",
       "0        is       set     local  resident         jeff  \n",
       "1       set     local  resident      jeff            a  \n",
       "2     local  resident      jeff         a       former  \n",
       "3  resident      jeff         a    former  psychiatric  \n",
       "\n",
       "[4 rows x 26 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(text_sequences[1:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "\n",
    "The next step is to encode these character sequences as numerical features. We do this using the [`Tokenizer`](https://keras.io/preprocessing/text/) object from Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numeric sequences.\n",
    "sequences = tokenizer.texts_to_sequences(text_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the first sequence is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 12586,\n",
       " 12585,\n",
       " 2397,\n",
       " 2,\n",
       " 12584,\n",
       " 5,\n",
       " 1,\n",
       " 5558,\n",
       " 630,\n",
       " 2195,\n",
       " 2927,\n",
       " 20,\n",
       " 1,\n",
       " 449,\n",
       " 157,\n",
       " 5,\n",
       " 12583,\n",
       " 7487,\n",
       " 42,\n",
       " 1,\n",
       " 117,\n",
       " 7,\n",
       " 362,\n",
       " 231,\n",
       " 2928]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us verify the first work of the sequence is \"in\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_word[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us save the vocabulary size = # unique tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12586"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size = len(tokenizer.word_counts)\n",
    "\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We store the sequences in a numpy array.\n",
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    8, 12586, 12585, ...,   362,   231,  2928],\n",
       "       [12586, 12585,  2397, ...,   231,  2928,   297],\n",
       "       [12585,  2397,     2, ...,  2928,   297,     4],\n",
       "       ...,\n",
       "       [   20,     4,  1551, ...,     1,    59,     5],\n",
       "       [    4,  1551,  1684, ...,    59,     5,     6],\n",
       "       [ 1551,  1684,    22, ...,     5,     6,   169]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X - y Split \n",
    "\n",
    "We now construct the observation matrix `X` and the label vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    8, 12586, 12585, ...,     7,   362,   231],\n",
       "       [12586, 12585,  2397, ...,   362,   231,  2928],\n",
       "       [12585,  2397,     2, ...,   231,  2928,   297],\n",
       "       ...,\n",
       "       [   20,     4,  1551, ...,    22,     1,    59],\n",
       "       [    4,  1551,  1684, ...,     1,    59,     5],\n",
       "       [ 1551,  1684,    22, ...,    59,     5,     6]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# select all but last word indices.\n",
    "X = sequences[:, :-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165844, 25)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2928,  297,    4, ...,    5,    6,  169])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select all last word indices.\n",
    "y = sequences[:, -1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Covert to categorical (we add + 1 because Keras needs a placeholder).\n",
    "y = to_categorical(y, num_classes=(vocabulary_size + 1))\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "Next, we define the (Sequential) network architecture:\n",
    "\n",
    "- [Embedding](https://keras.io/layers/embeddings/) layer.\n",
    "- Two [LSTM](https://keras.io/layers/recurrent/#lstm) layers.\n",
    "- One Dense layer with `relu` activation function.\n",
    "- One final Dense layer with `softmax` activation function to output class probabilities.\n",
    "\n",
    "As a reminder, here is a schema of an LSTM layer:\n",
    "\n",
    "<img src=\"LSTM_Schema.png\" height=\"10\" alt=\"Alt text that describes the graphic\" title=\"Title text\"/>\n",
    "\n",
    "Image Source: [Deep Learning with R](https://www.manning.com/books/deep-learning-with-r), page 188.\n",
    "\n",
    "\n",
    "\n",
    "For the optimization: \n",
    "\n",
    "- loss ='categorical_crossentropy' \n",
    "- optimizer = 'adam', \n",
    "- metrics = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "\n",
    "def create_model(vocabulary_size, seq_len):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim=vocabulary_size, \n",
    "                        output_dim=seq_len, \n",
    "                        input_length=seq_len))\n",
    "    \n",
    "    model.add(LSTM(units=50, return_sequences=True))\n",
    "    \n",
    "    model.add(LSTM(units=50))\n",
    "    \n",
    "    model.add(Dense(units=50, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(units=vocabulary_size, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 25, 25)            314675    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 25, 50)            15200     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12587)             641937    \n",
      "=================================================================\n",
      "Total params: 994,562\n",
      "Trainable params: 994,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let us create the model and see summary.\n",
    "model = create_model(vocabulary_size=(vocabulary_size + 1), seq_len=seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I fit the model in my local machine. With a batch_sise of 128 it took 700 epochs to get an accuracy of around 0.5 (which is ok as our aim is not correcly classify all sequences) and it took around 8 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=X, y=y, batch_size=128, epochs=700, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165844/165844 [==============================] - 48s 292us/step\n"
     ]
    }
   ],
   "source": [
    "# Get model metrics.\n",
    "loss, accuracy =  model.evaluate(x=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.388542058993397\n",
      "Accuracy: 0.4952485468285764\n"
     ]
    }
   ],
   "source": [
    "print(f'Loss: {loss}\\nAccuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model\n",
    "\n",
    "First we save the `tokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "\n",
    "dump(tokenizer, open('tokenizer', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reload the model as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate New Text\n",
    "\n",
    "Now we can use the model to generate new word sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences \n",
    "\n",
    "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "    # List to store the generated words. \n",
    "    output_text = []\n",
    "    # Set seed_text as input_text. \n",
    "    input_text = seed_text\n",
    "    \n",
    "    for i in range(num_gen_words):\n",
    "        # Encode input text. \n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        # Add if the input tesxt does not have length len_0.\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "        # Do the prediction. Here we automatically choose the word with highest probability. \n",
    "        pred_word_ind = model.predict_classes(pad_encoded, verbose=0)[0]\n",
    "        # Convert from numeric to word. \n",
    "        pred_word = tokenizer.index_word[pred_word_ind]\n",
    "        # Attach predicted word. \n",
    "        input_text += ' ' + pred_word\n",
    "        # Append new word to the list. \n",
    "        output_text.append(pred_word)\n",
    "        \n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how this works in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "Select a subset of out training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Officer Frank Williams (Steven Vidler) and his partner Blaine investigate an abandoned house, where they find a young woman with her eyes ripped out. A large figure with an axe then murders Blaine and Frank has his arm chopped off before he is able to shoot the attacker in the head. Afterwards, detectives find seven bodies in the house, all of which have had their eyes ripped out.\n"
     ]
    }
   ],
   "source": [
    "sample_text = horror_df.iloc[100][:383]\n",
    "print(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `seed_text` to be the start of the `sample test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Officer Frank Williams (Steven Vidler) and his partner Blaine investigate an abandoned house, where they find a young woman with her eyes ripped out. A large figure with an axe then murders \n"
     ]
    }
   ],
   "source": [
    "seed_text = sample_text[:190]\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cocky college football star Francis Finnegan has his eye on the attractive Gloria van Dayham, as does his rival, Larry Stacey.\r\n",
      "Francis gets a job in a department store owned by Stacey's father, where salesgirl June Cort develops an attraction to him. Finnegan proposes that Stacey's store sponsor a football team, which causes rival shop owner Whimple to do likewise. The team's head cheerleader, Mimi, falls for team mascot Joe, meanwhile, and everybody pairs off with the perfect partner after the big game. and kills ziko is eaten but jenna learn of thrill village on a punk couple of the house and puts her to the island and erin are instructed to get beside chaos ambrosia might can trust him he gone to...\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text(model=model, \n",
    "                               tokenizer=tokenizer,\n",
    "                               seq_len=seq_len, \n",
    "                               seed_text=seed_text, \n",
    "                               num_gen_words=40)\n",
    "\n",
    "print(seed_text + ' ' + generated_text + '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "Let us give a \"horror-like\" seed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = 'the film starts in a dark house where a group of teenagers friends meet to spend the weekend when they suddenly hear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the film starts in a dark house where a group of teenagers friends meet to spend the weekend when they suddenly hear voices he confronts john 's mother and lina pull themselves into the morning because the group split her face towards the scene and attempts to shoot the supervision of the truth jessabelle 's throat with regular injections of them and remains by itself blocks nazi isolating youths 's grave and tortures him are inferior in coffins and a group of the entire bat acting in los angeles with the ghosts of the same time and lures her drugs in 1408...\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text(model=model, \n",
    "                               tokenizer=tokenizer,\n",
    "                               seq_len=seq_len, \n",
    "                               seed_text=seed_text, \n",
    "                               num_gen_words=80)\n",
    "\n",
    "print(seed_text + ' ' + generated_text + '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "\n",
    "Now let us start with a \"comedy-type\" seed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cocky college football star Francis Finnegan has his eye on the attractive Gloria van Dayham, as does his rival, Larry Stacey.\r\n",
      "Francis gets a job in a department store owned by Stacey's father, where salesgirl June Cort develops an attraction to him. Finnegan proposes that Stacey's store sponsor a football team, which causes rival shop owner Whimple to do likewise. The team's head cheerleader, Mimi, falls for team mascot Joe, meanwhile, and everybody pairs off with the perfect partner after the big game.\n"
     ]
    }
   ],
   "source": [
    "seed_text = movies_raw_df[movies_raw_df['Genre'] == 'comedy']['Plot'].iloc[330]\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the film starts in a dark house where a group of teenagers friends meet to spend the weekend when they suddenly hear voices he confronts john 's mother and lina pull themselves into the morning because the group split her face towards the scene and attempts to shoot the supervision of the truth jessabelle 's throat with regular injections of them and remains by itself blocks nazi isolating youths 's grave and tortures him are inferior in coffins and a group of the entire bat acting in los angeles with the ghosts of the same time and lures her drugs in 1408 of ice police carrie remembers biting a minutes of a...\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text(model=model, \n",
    "                               tokenizer=tokenizer,\n",
    "                               seq_len=seq_len, \n",
    "                               seed_text=seed_text, \n",
    "                               num_gen_words=90)\n",
    "\n",
    "print(seed_text + ' ' + generated_text + '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the generated text seem to have structure. Nevrtheless, somethimes these sentences do not make a lot of sense. Quoting from [Deep Learning with R](https://www.manning.com/books/deep-learning-with-r), page 260:\n",
    "\n",
    "*But, of course, don't expect to ever generate any meaningfull text, other than by random chance: all you're doing is sampling data from a statistical model of which ~~characters~~ words come after which ~~characters~~ words.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, in the `generate_text` function we are not sampling, but rather selecting the word with highest probability. We can relax this by really sampling over the learned distribution. Moreover, we can introduce a parameter, known as `temperature` $T\\in[0,1]$, which spreads it to get more \"creative\" results. Concretely, let $x$ be the vector distribution. Consider the transformation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f_{T}(x) = C \\exp(\\log(x)/T), \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $C>0$ is just a normalization constant. Note that for $T=1$ we just get the identity transformation. Observe that we can simplify $f_T$ using the relaton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\exp(\\log(x)/T) = (\\exp(\\log(x)))^{1/T} = x^{1/T}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us include these changes into a new text generation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text2(model, tokenizer, seq_len, seed_text, num_gen_words, temperature):\n",
    "    \n",
    "    output_text = []\n",
    "    \n",
    "    input_text = seed_text\n",
    "    \n",
    "    for i in range(num_gen_words):\n",
    "        # Encode input text. \n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "         # Add if the input tesxt does not have length len_0.\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "        # Get learned distribution.\n",
    "        pred_distribution = model.predict(pad_encoded, verbose=0)[0]\n",
    "        \n",
    "        # Apply temperature transformation.\n",
    "        new_pred_distribution = np.power(pred_distribution, (1 / temperature)) \n",
    "        new_pred_distribution = new_pred_distribution / new_pred_distribution.sum()\n",
    "        \n",
    "        # Sample from modified distribution.\n",
    "        choices = range(new_pred_distribution.size)\n",
    " \n",
    "        pred_word_ind = np.random.choice(a=choices, p=new_pred_distribution)\n",
    "        \n",
    "        # Convert from numeric to word. \n",
    "        pred_word = tokenizer.index_word[pred_word_ind]\n",
    "        # Attach predicted word. \n",
    "        input_text += ' ' + pred_word\n",
    "        # Append new word to the list. \n",
    "        output_text.append(pred_word)\n",
    "        \n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2 - Revisited. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = 'the film starts in a dark house where a group of teenagers friends meet to spend the weekend when they suddenly hear'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `temperature` = $0.9$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the film starts in a dark house where a group of teenagers friends meet to spend the weekend when they suddenly hear noises the next day owen stabs his seventh when sophie shoots her in the search such he subdues him exist pulls her bloody late eliot then discover that he can do so of kristi so will be letting her that that he had some friends constantly slicing away by confronted by nikki who to the hospital anna is stuck in a switch who grip thomas drains a incident that he strikes justin from frustration and learn it do so that ...\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text2(model=model, \n",
    "                                tokenizer=tokenizer,\n",
    "                                seq_len=seq_len, \n",
    "                                seed_text=seed_text, \n",
    "                                num_gen_words=80, \n",
    "                                temperature=0.9)\n",
    "\n",
    "print(seed_text + ' ' + generated_text + ' ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `temperature` = $0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the film starts in a dark house where a group of teenagers friends meet to spend the weekend when they suddenly hear voices that she looks up the others the next morning kaylie is scared from her bed and runs to a mayan butcher and romania to the pile and lures drake into a household project pleased kid rescue spaulding at the fireplace and clutching a corvinus time who has been on a stake and frantically try to swim her the explosion begins to be still alive a couple however detective william checks tourists horror and cryogenic fictional camera in the bodega chair severing ...\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text2(model=model, \n",
    "                                tokenizer=tokenizer,\n",
    "                                seq_len=seq_len, \n",
    "                                seed_text=seed_text, \n",
    "                                num_gen_words=82, \n",
    "                                temperature=0.5)\n",
    "\n",
    "print(seed_text + ' ' + generated_text + ' ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `temperature` = $0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the film starts in a dark house where a group of teenagers friends meet to spend the weekend when they suddenly hear voices he confronts john 's mother and lina pull themselves into the morning because the group split her face towards the scene and attempts to shoot the road and is really contains numerous louisiana to stop them in the basement and kills her and that she tries to leave the baxter hook smashing six o'connell dust terrifying to battery loosen from a woman suit to relax john daphne distracting her out to plead reassured that she 's computer is sucked into by ...\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text2(model=model, \n",
    "                                tokenizer=tokenizer,\n",
    "                                seq_len=seq_len, \n",
    "                                seed_text=seed_text, \n",
    "                                num_gen_words=82, \n",
    "                                temperature = 0.1)\n",
    "\n",
    "print(seed_text + ' ' + generated_text + ' ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "\n",
    "As mentioned in the introduction, this is just the first step in the model iteration. Next iterations can include (among many other things):\n",
    "\n",
    "- Experiment with different number of neurons per layer.\n",
    "- Try new network architecture, for example adding a 1D-convnet layer.\n",
    "- Train on a bigger data set. \n",
    "\n",
    "Of course, training on GPU would allow us to iterate faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
