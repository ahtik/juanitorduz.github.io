<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python Statistics on Dr. Juan Camilo Orduz</title>
    <link>/tags/python-statistics/</link>
    <description>Recent content in Python Statistics on Dr. Juan Camilo Orduz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 08 Apr 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/python-statistics/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>An Introduction to Gaussian Process Regression</title>
      <link>/gaussian_process_reg/</link>
      <pubDate>Mon, 08 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/gaussian_process_reg/</guid>
      <description>After a sequence of preliminary posts (Sampling from a Multivariate Normal Distribution and Regularized Bayesian Regression as a Gaussian Process), I want to expole a concrete example of a gaussian process regression. We continue following Gaussian Processes for Machine Learning, Ch 2, by C. E. Rasmussen and C. K. I. Williams. Another recomended reference is the work on Gaussian Processes for Timeseries Modeling by S. Roberts, M. Osborne, M. Ebden, S.</description>
    </item>
    
    <item>
      <title>Regularized Bayesian Regression as a Gaussian Process</title>
      <link>/reg_bayesian_regression/</link>
      <pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/reg_bayesian_regression/</guid>
      <description>In this post we study the Regularized Bayesian Regression model to explore and compare the weight and function space and views of Gaussian Process Regression as described in the book Gaussian Processes for Machine Learning, Ch 2. We follow this reference very closely (and encourage to read it!). Our main objective is to illustrate the concepts and results through a concrete example. We use PyMC3 to run bayesian sampling.</description>
    </item>
    
    <item>
      <title>Sampling from a Multivariate Normal Distribution</title>
      <link>/multivariate_normal/</link>
      <pubDate>Sat, 23 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/multivariate_normal/</guid>
      <description>In this post I want to describe how to sample from a multivariate normal distribution following section A.2 Gaussian Identities of the book Gaussian Processes for Machine Learning. This is a first step towards exploring and understanding Gaussian Processes methods in machine learning.
Multivariate Normal Distribution Recall that a random vector \(X = (X_1, \cdots, X_d)\) has a multivariate normal (or Gaussian) distribution if every linear combination
$$ \sum_{i=1}^{d} a_iX_i, \quad a_i\in\mathbb{R} $$ is normally distributed.</description>
    </item>
    
  </channel>
</rss>